# BeyondChats Assignment

![Architecture](readmeassert/architecture.png)
A production-style system that scrapes live blog articles, stores them, runs an AI-style enhancement pipeline, and displays both versions (original vs enhanced) like a before/after content makeover.

ğŸ‘‡ Live Demo â€” fully deployed & talking to each other

Layer	Live URL
ğŸ¨ Frontend	https://beyondchats-assignment-q4n2cmcs5-barathraj048s-projects.vercel.app/

âš™ï¸ Backend API	https://beyondchats-assignment-hd7d.onrender.com/api/health
ğŸ§  What This Project Does (TL;DR)
Step	Action	Layer
1ï¸âƒ£	Scrape 5 blogs from BeyondChats site	Node.js + Cheerio
2ï¸âƒ£	Store them in DB via REST API	Laravel
3ï¸âƒ£	Enhance missing ones via pipeline	Mock AI (LLM-ready)
4ï¸âƒ£	Show original + enhanced versions	React + Tailwind

âœ” Modular | âœ” Production-minded | âœ” LLM ready | âœ” Partial Phase-2 implemented

ğŸ—ï¸ System Architecture
 Scraper (Node.js)
        â¬‡
 Backend API (Laravel) â†’ SQLite DB
        â¬†
 AI Enhancer (Node.js, LLM-Ready)
        â¬†
 Frontend (React + Vite + Tailwind)


Each service is independent â†’ can scale, break or deploy separately like real SaaS.

âš™ï¸ Tech Stack
Layer	Tech
Backend API	Laravel 12, PHP 8.3, SQLite
Frontend	React + TypeScript + Vite
Scraper	Node.js + Cheerio
AI Engine	Mock LLM pipeline (DeepSeek/GPT-ready)
Deployments	Render (Docker) for backend, Vercel for frontend
Styling	TailwindCSS
ğŸŒ Deployment
ğŸ¯ Backend â€” Render (Docker)

https://beyondchats-assignment-hd7d.onrender.com

/api/health â†’ returns system status

SQLite persisted in container

Served with Apache + PHP 8.3

ğŸ¯ Frontend â€” Vercel

https://beyondchats-assignment-q4n2cmcs5-barathraj048s-projects.vercel.app/

Rebuilds on push to main

ğŸ’» Run Locally
Backend (Laravel)
cd backend
composer install
cp .env.example .env
php artisan key:generate
php artisan migrate
php artisan serve

Scrape Articles
cd scraper
npm install
node scraper.js

Enhance via AI (Mock)
node aiEnhancer.js

Frontend
cd frontend
npm install
npm run dev


â¡ï¸ If backend is local, update:
frontend/src/config.js

export const API_BASE = "http://127.0.0.1:8000/api";

ğŸ”Œ API Reference
Method	Endpoint	Purpose
GET	/api/health	Health check
GET	/api/articles	Fetch all articles
POST	/api/articles	Scraper saves new articles
PUT	/api/articles/{id}/enhance	Update enhanced version
GET	/api/articles/count	How many saved
GET	/api/articles/exists?title=	Avoid duplicates
ğŸ—„ï¸ Database Schema (SQLite)

articles

id                INTEGER (PK)
title             TEXT
content           TEXT               // original HTML/text
updated_content   TEXT NULL          // AI enhanced
source            TEXT
created_at
updated_at


Stores HTML, not plain text â†’ better for AI formatting & SEO.

ğŸ¯ Why I Built It This Way
Choice	Why
Separate pipelines	Background jobs shouldn't block API
HTML storage	Preserves UX + content semantics
SQLite	Simple deploy â†’ can move to PostgreSQL easily
Docker for backend	Same environment local & cloud
Mock AI pipeline	LLM-ready without billing
ğŸ©¹ Challenges â†’ Solutions
Problem	What broke	Fix
Scraper missing content	inconsistent markup	Selector fallback & multi-pass parsing
CORS blocking frontend	API rejected requests	Configured Laravel CORS middleware
Render wiping DB	Ephemeral FS issue	Moved to container SQLite path
ğŸ§  Phase-2 Scope Status (Assignment Requirement)
Requirement	Status
Fetch latest article	âœ” Done
Google search for competitors	âŒ (Skipped - would need paid API & scraping risk)
Scrape 2 competitor articles	âŒ (Prepped infra, not executed)
Call LLM API for enhancement	âš ï¸ Mocked (LLM-ready)
Save enhanced version	âœ” Done
Cite reference links	âŒ (LLM step pending)

ğŸ“Œ Summary:
â¡ï¸ Architecture + pipeline ready.
â¡ï¸ LLM and Google step intentionally skipped to avoid cost / TOS issues.
â¡ï¸ This is acceptable as per assignmentâ€™s â€œpartial OKâ€ rule.

ğŸ§± Repo Structure
beyondchats-assignment/
â”œâ”€â”€ backend/           # Laravel API
â”œâ”€â”€ frontend/          # React + Vite UI
â”œâ”€â”€ scraper/           # Scraper + AI pipeline
â”œâ”€â”€ readmeassert/      # Architecture diagram
â””â”€â”€ README.md

ğŸš€ Future Enhancements

Plug real GPT / Claude / DeepSeek

Add cron jobs / queue workers

Retry & backoff logic for scraping

Article versioning â†’ history of enhancements

PostgreSQL migration

ğŸ‘‹ Author

Bharath Raj
Full-stack engineer â†’ end-to-end ownership, debugging real systems, shipping to production.

ğŸ’¼ GitHub: https://github.com/barathraj048

ğŸ§  LinkedIn: pending update with case study